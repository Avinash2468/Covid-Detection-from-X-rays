{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 99,
     "referenced_widgets": [
      "584424c415974ffcaa57b0edabfb935f",
      "033ba8d1a4c2449096a0aa411f15e5a1",
      "fe916e4124e445bb94b8e793ef10b4da",
      "f340498a1f134a61994d9fa7cca7a5ac",
      "e96a369280d04ff2afbc6a21e21fdd9c",
      "fbae6d6f42764431b264159951494b4f",
      "0ef40ac1e3d843df89ee5335d5e823aa",
      "d21fe11619044580a636962bbbb12c3f"
     ]
    },
    "id": "KKh1IFKNmL0K",
    "outputId": "ecc59376-cca3-48dd-f478-15c1887cff94"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "584424c415974ffcaa57b0edabfb935f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=553507836.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import ast\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "import PIL\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from torchvision import models\n",
    "vgg16 = models.vgg16_bn(pretrained=True)\n",
    "\n",
    "\n",
    "plt.ion()  \n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"Using CUDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pk4QtqEHnziU",
    "outputId": "4d0d0e99-1743-4999-b796-5a4bc7b0cd3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3uLd4gNRoX6Y",
    "outputId": "1e693e55-6be1-4e00-9851-492544ac591c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive\n"
     ]
    }
   ],
   "source": [
    "% cd drive/My\\ Drive/\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dq2WQwAyK3HP",
    "outputId": "79d1acaf-32fa-44e4-abf2-2dbcd96185d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CULPRIT\n",
      "CULPRIT\n",
      "CULPRIT\n",
      "CULPRIT\n",
      "CULPRIT\n",
      "CULPRIT\n",
      "CULPRIT\n",
      "CULPRIT\n",
      "CULPRIT\n",
      "CULPRIT\n",
      "CULPRIT\n",
      "CULPRIT\n",
      "CULPRIT\n",
      "CULPRIT\n",
      "CULPRIT\n",
      "CULPRIT\n",
      "CULPRIT\n",
      "CULPRIT\n",
      "CULPRIT\n",
      "CULPRIT\n",
      "CULPRIT\n"
     ]
    }
   ],
   "source": [
    "# Preparing the dataset\n",
    "f=pd.read_csv(\"./covid-chestxray-dataset/metadata.csv\")\n",
    "keep_col = ['sex','age','finding','view','filename']\n",
    "new_f = f[keep_col]\n",
    "new_f.to_csv(\"./covid-chestxray-dataset/metadata_final.csv\", index=False)\n",
    "\n",
    "df = pd.read_csv(\"./covid-chestxray-dataset/metadata_final.csv\")\n",
    "\n",
    "df[df.finding != 'todo']\n",
    "df[df.view != 'AP Erect'] # Not enough data\n",
    "df = df.dropna()\n",
    "\n",
    "listie = []\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    test_img = cv2.imread('./covid-chestxray-dataset/images/'+row['filename'])\n",
    "\n",
    "    if test_img is None:\n",
    "      print(\"CULPRIT\")\n",
    "      listie.append(row['filename'])\n",
    "\n",
    "    text = row['finding']\n",
    "    # print(text)\n",
    "    text_split = text.split(\"/\")\n",
    "\n",
    "    if 'COVID-19' in text_split:\n",
    "      df.loc[index,'finding'] = '[1,0]'\n",
    "    else:\n",
    "      df.loc[index,'finding'] = '[0,1]'\n",
    "    \n",
    "    if row['sex'] == 'M':\n",
    "      df.loc[index,'sex'] = 0\n",
    "    else:\n",
    "      df.loc[index,'sex'] = 1\n",
    "\n",
    "    df.loc[index,'age'] = row['age']/100\n",
    "\n",
    "    if row['view'] == 'AP':\n",
    "       df.loc[index,'view'] = '[1,0,0,0,0,0]'\n",
    "    elif row['view'] == 'PA':\n",
    "      df.loc[index,'view'] = '[0,1,0,0,0,0]'\n",
    "    elif row['view'] == 'L':\n",
    "      df.loc[index,'view'] = '[0,0,1,0,0,0]'\n",
    "    elif row['view'] == 'Axial':\n",
    "      df.loc[index,'view'] = '[0,0,0,1,0,0]'\n",
    "    elif row['view'] == 'AP Supine':\n",
    "      df.loc[index,'view'] = '[0,0,0,0,1,0]'\n",
    "    elif row['view'] == 'Coronal':\n",
    "      df.loc[index,'view'] = '[0,0,0,0,0,1]'\n",
    "    # print(row['finding'])\n",
    "    # print(row['sex'], row['age'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-rF31-bBHn-y",
    "outputId": "b96d14f1-57c4-4653-b9c7-64fa256f6475"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "radiopaedia_org_covid-19-pneumonia-7_85703_0-dcm.nii.gz\n",
      "radiopaedia_org_covid-19-pneumonia-14_85914_0-dcm.nii.gz\n",
      "coronacases_org_001.nii.gz\n",
      "coronacases_org_002.nii.gz\n",
      "coronacases_org_003.nii.gz\n",
      "coronacases_org_004.nii.gz\n",
      "coronacases_org_005.nii.gz\n",
      "coronacases_org_006.nii.gz\n",
      "coronacases_org_007.nii.gz\n",
      "coronacases_org_008.nii.gz\n",
      "coronacases_org_009.nii.gz\n",
      "coronacases_org_010.nii.gz\n",
      "radiopaedia_org_covid-19-pneumonia-4_85506_1-dcm.nii.gz\n",
      "radiopaedia_org_covid-19-pneumonia-29_86490_1-dcm.nii.gz\n",
      "radiopaedia_org_covid-19-pneumonia-29_86491_1-dcm.nii.gz\n",
      "radiopaedia_org_covid-19-pneumonia-23_86359_0-dcm.nii.gz\n",
      "radiopaedia_org_covid-19-pneumonia-10_85902_1-dcm.nii.gz\n",
      "radiopaedia_org_covid-19-pneumonia-10_85902_3-dcm.nii.gz\n",
      "radiopaedia_org_covid-19-pneumonia-36_86526_0-dcm.nii.gz\n",
      "radiopaedia_org_covid-19-pneumonia-27_86410_0-dcm.nii.gz\n",
      "radiopaedia_org_covid-19-pneumonia-40_86625_0-dcm.nii.gz\n"
     ]
    }
   ],
   "source": [
    "for ii in listie:\n",
    "  print(ii)\n",
    "  df.drop(df.loc[df['filename']==ii].index, inplace=True)\n",
    "df.to_csv('./covid-chestxray-dataset/metadata_final2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kBuOvsi4vH-w"
   },
   "outputs": [],
   "source": [
    "# Defining the required transformations for our custom data\n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, sex, age, finding, view = sample['image'], sample['sex'], sample['age'], sample['finding'], sample['view']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "\n",
    "        # h and w are swapped for landmarks because for images,\n",
    "        # x and y axes are axis 1 and 0 respectively\n",
    "        # landmarks = landmarks * [new_w / w, new_h / h]\n",
    "\n",
    "        return {'image': img, 'sex': sex, 'age': age, 'finding':finding, 'view':view}\n",
    "\n",
    "\n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, sex, age, finding, view = sample['image'], sample['sex'], sample['age'], sample['finding'], sample['view']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "        # landmarks = landmarks - [left, top]\n",
    "\n",
    "        return {'image': image, 'sex': sex, 'age': age, 'finding':finding, 'view':view}\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, sex, age, finding, view = sample['image'], sample['sex'], sample['age'], sample['finding'], sample['view']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        # print(image.shape)\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image).float(),\n",
    "                'sex': torch.from_numpy(sex),\n",
    "                'age': torch.from_numpy(age).float(),\n",
    "                'finding': torch.from_numpy(finding),\n",
    "                'view': torch.from_numpy(view)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PTOMFUmHe-z-"
   },
   "outputs": [],
   "source": [
    "# Loading the data from the folders\n",
    "\n",
    "class FaceLandmarksDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.landmarks_frame.iloc[idx, 5])\n",
    "        # print(img_name)\n",
    "        image = cv2.imread(img_name)\n",
    "        # plt.imshow(image)\n",
    "        # plt.show()\n",
    "        sample = 0\n",
    "\n",
    "        # print(image.shape)\n",
    "        sex = self.landmarks_frame.iloc[idx,1]\n",
    "        age = self.landmarks_frame.iloc[idx, 2]\n",
    "        finding = self.landmarks_frame.iloc[idx, 3]\n",
    "        view = self.landmarks_frame.iloc[idx, 4]\n",
    "        view = ast.literal_eval(view)\n",
    "        finding = ast.literal_eval(finding)\n",
    "\n",
    "        sample = {'image': np.asarray(image), 'sex': np.asarray(sex), 'age': np.asarray(age), 'finding':np.asarray(finding), 'view':np.asarray(view)}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QxQ99O_YxGcT"
   },
   "outputs": [],
   "source": [
    "# The original dataset\n",
    "face_dataset = FaceLandmarksDataset(csv_file='./covid-chestxray-dataset/metadata_final2.csv',\n",
    "                                    root_dir='./covid-chestxray-dataset/images')\n",
    "\n",
    "# The transformed dataset\n",
    "transformed_dataset = FaceLandmarksDataset(csv_file='./covid-chestxray-dataset/metadata_final2.csv',\n",
    "                                    root_dir='./covid-chestxray-dataset/images',transform=transforms.Compose([\n",
    "                                               Rescale(256),\n",
    "                                               RandomCrop(224),\n",
    "                                               ToTensor()\n",
    "                                           ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qEl4bKC4BP3",
    "outputId": "d5a0dc57-299c-4a3a-bbab-5a2cca715058"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601\n"
     ]
    }
   ],
   "source": [
    "# Sanity check, we will check if our model is overfitting, we will be taking 4 images per class\n",
    "train_set, val_set = torch.utils.data.random_split(transformed_dataset, [601, 67])\n",
    "print(len(train_set))\n",
    "\n",
    "overfit_trainset = []\n",
    "overfit_valset = []\n",
    "# output\n",
    "counter = np.zeros((1,2))\n",
    "pointer = -1\n",
    "for i in range(len(train_set)):\n",
    "  # print(counter)\n",
    "  # print(train_set[i]['finding'])\n",
    "  # print(int(train_set[i]['finding'].max(0, keepdim=True)[1]))\n",
    "  if counter[0,0] == 11 and counter[0,1] == 11:\n",
    "    break\n",
    "  if (counter[0,int(train_set[i]['finding'].max(0, keepdim=True)[1])]<11):\n",
    "    overfit_trainset.append(train_set[i])\n",
    "    counter[0,int(train_set[i]['finding'].max(0, keepdim=True)[1])]+=1\n",
    "\n",
    "# print(\"OVER\")\n",
    "# print(overfit_trainset)\n",
    "counter = np.zeros((1,2))\n",
    "pointer = -1\n",
    "for i in range(len(val_set)):\n",
    "  # print(val_set[i]['finding'])\n",
    "  # print(int(val_set[i]['finding'].max(0, keepdim=True)[1]))\n",
    "  # print(counter)\n",
    "  if counter[0,0] == 6 and counter[0,1] == 6:\n",
    "    break\n",
    "  if (counter[0,int(val_set[i]['finding'].max(0, keepdim=True)[1])]<6):\n",
    "    overfit_valset.append(val_set[i])\n",
    "    counter[0,int(val_set[i]['finding'].max(0, keepdim=True)[1])]+=1\n",
    "\n",
    "\n",
    "# print(overfit_valset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OvwAnb9y9JqY"
   },
   "outputs": [],
   "source": [
    "# Load the pretrained model from pytorch\n",
    "vgg16 = models.vgg16_bn()\n",
    "vgg16.load_state_dict(torch.load(\"/root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\", map_location=\"cuda:0\"))\n",
    "\n",
    "# Freeze training for all layers\n",
    "for param in vgg16.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "vgg_extract = vgg16.features\n",
    "\n",
    "class Feature_Extractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Feature_Extractor, self).__init__()\n",
    "        self.extractor = vgg_extract\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.extractor(x)\n",
    "        # print(x.shape)\n",
    "        # print(x.requires_grad)\n",
    "        return x\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(25096, 4096, bias=False)\n",
    "        self.fc2 = nn.Linear(4096, 4096, bias=True)\n",
    "        self.fc3 = nn.Linear(4096, 128, bias=True)\n",
    "        self.fc4 = nn.Linear(128, 2, bias=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        layer1 = F.relu(self.fc1(x))\n",
    "        # print(layer1.requires_grad)\n",
    "        layer2 = F.relu(self.fc2(self.dropout(layer1)))\n",
    "        # print(layer2.requires_grad)\n",
    "        layer3 = F.relu(self.fc3(self.dropout(layer1)))\n",
    "        # print(layer3.requires_grad)\n",
    "        layer4 = self.fc4(layer3)\n",
    "        # print(layer4.requires_grad)\n",
    "        return layer4\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(25096, 4096, bias=False)\n",
    "        self.fc2 = nn.Linear(4096, 4096, bias=True)\n",
    "        self.fc3 = nn.Linear(4096, 128, bias=True)\n",
    "        self.fc4 = nn.Linear(128, 2, bias=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        layer1 = F.relu(self.fc1(x))\n",
    "        # print(layer1.requires_grad)\n",
    "        layer2 = F.relu(self.fc2(self.dropout(layer1)))\n",
    "        # print(layer2.requires_grad)\n",
    "        layer3 = F.relu(self.fc3(self.dropout(layer1)))\n",
    "        # print(layer3.requires_grad)\n",
    "        layer4 = self.fc4(layer3)\n",
    "        # print(layer4.requires_grad)\n",
    "        return layer4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I7OP9RasafAq",
    "outputId": "a17f25f0-9ca3-4bb0-b3f5-7df3345ef48b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH NUMBER: 0\n",
      "Avg loss (train): 0.0842\n",
      "Avg acc (train): 0.5874\n",
      "saved\n",
      "Avg loss (val): 0.0621\n",
      "Avg acc (val): 0.6716\n",
      "\n",
      "EPOCH NUMBER: 1\n",
      "Avg loss (train): 0.0791\n",
      "Avg acc (train): 0.6456\n",
      "Avg loss (val): 0.0526\n",
      "Avg acc (val): 0.6716\n",
      "\n",
      "EPOCH NUMBER: 2\n",
      "Avg loss (train): 0.0726\n",
      "Avg acc (train): 0.7155\n",
      "saved\n",
      "Avg loss (val): 0.0456\n",
      "Avg acc (val): 0.7015\n",
      "\n",
      "EPOCH NUMBER: 3\n",
      "Avg loss (train): 0.0666\n",
      "Avg acc (train): 0.7521\n",
      "saved\n",
      "Avg loss (val): 0.1311\n",
      "Avg acc (val): 0.7164\n",
      "\n",
      "EPOCH NUMBER: 4\n",
      "Avg loss (train): 0.0606\n",
      "Avg acc (train): 0.7870\n",
      "Avg loss (val): 0.0112\n",
      "Avg acc (val): 0.6866\n",
      "\n",
      "EPOCH NUMBER: 5\n",
      "Avg loss (train): 0.0536\n",
      "Avg acc (train): 0.8236\n",
      "Avg loss (val): 0.0524\n",
      "Avg acc (val): 0.7015\n",
      "\n",
      "EPOCH NUMBER: 6\n",
      "Avg loss (train): 0.0479\n",
      "Avg acc (train): 0.8469\n",
      "Avg loss (val): 0.0157\n",
      "Avg acc (val): 0.7164\n",
      "\n",
      "EPOCH NUMBER: 7\n",
      "Avg loss (train): 0.0416\n",
      "Avg acc (train): 0.8602\n",
      "saved\n",
      "Avg loss (val): 0.0313\n",
      "Avg acc (val): 0.7313\n",
      "\n",
      "EPOCH NUMBER: 8\n",
      "Avg loss (train): 0.0429\n",
      "Avg acc (train): 0.8586\n",
      "Avg loss (val): 0.0307\n",
      "Avg acc (val): 0.7015\n",
      "\n",
      "EPOCH NUMBER: 9\n",
      "Avg loss (train): 0.0389\n",
      "Avg acc (train): 0.8752\n",
      "Avg loss (val): 0.0117\n",
      "Avg acc (val): 0.6567\n",
      "\n",
      "EPOCH NUMBER: 10\n",
      "Avg loss (train): 0.0396\n",
      "Avg acc (train): 0.8752\n",
      "saved\n",
      "Avg loss (val): 0.0196\n",
      "Avg acc (val): 0.8358\n",
      "\n",
      "EPOCH NUMBER: 11\n",
      "Avg loss (train): 0.0297\n",
      "Avg acc (train): 0.9068\n",
      "Avg loss (val): 0.0003\n",
      "Avg acc (val): 0.7463\n",
      "\n",
      "EPOCH NUMBER: 12\n",
      "Avg loss (train): 0.0322\n",
      "Avg acc (train): 0.8968\n",
      "Avg loss (val): 0.0030\n",
      "Avg acc (val): 0.7463\n",
      "\n",
      "EPOCH NUMBER: 13\n",
      "Avg loss (train): 0.0304\n",
      "Avg acc (train): 0.8935\n",
      "Avg loss (val): 0.0003\n",
      "Avg acc (val): 0.7761\n",
      "\n",
      "EPOCH NUMBER: 14\n",
      "Avg loss (train): 0.0260\n",
      "Avg acc (train): 0.9168\n",
      "Avg loss (val): 0.0001\n",
      "Avg acc (val): 0.7015\n",
      "\n",
      "EPOCH NUMBER: 15\n",
      "Avg loss (train): 0.0253\n",
      "Avg acc (train): 0.9151\n",
      "Avg loss (val): 0.0000\n",
      "Avg acc (val): 0.7910\n",
      "\n",
      "EPOCH NUMBER: 16\n",
      "Avg loss (train): 0.0225\n",
      "Avg acc (train): 0.9268\n",
      "Avg loss (val): 0.0990\n",
      "Avg acc (val): 0.7164\n",
      "\n",
      "EPOCH NUMBER: 17\n",
      "Avg loss (train): 0.0310\n",
      "Avg acc (train): 0.9002\n",
      "Avg loss (val): 0.0015\n",
      "Avg acc (val): 0.7313\n",
      "\n",
      "EPOCH NUMBER: 18\n",
      "Avg loss (train): 0.0283\n",
      "Avg acc (train): 0.9235\n",
      "Avg loss (val): 0.0092\n",
      "Avg acc (val): 0.7164\n",
      "\n",
      "EPOCH NUMBER: 19\n",
      "Avg loss (train): 0.0210\n",
      "Avg acc (train): 0.9384\n",
      "Avg loss (val): 0.0490\n",
      "Avg acc (val): 0.7463\n",
      "\n",
      "EPOCH NUMBER: 20\n",
      "Avg loss (train): 0.0383\n",
      "Avg acc (train): 0.8935\n",
      "Avg loss (val): 0.0003\n",
      "Avg acc (val): 0.6866\n",
      "\n",
      "EPOCH NUMBER: 21\n",
      "Avg loss (train): 0.0181\n",
      "Avg acc (train): 0.9468\n",
      "Avg loss (val): 0.0163\n",
      "Avg acc (val): 0.6716\n",
      "\n",
      "EPOCH NUMBER: 22\n",
      "Avg loss (train): 0.0221\n",
      "Avg acc (train): 0.9285\n",
      "Avg loss (val): 0.0001\n",
      "Avg acc (val): 0.6567\n",
      "\n",
      "EPOCH NUMBER: 23\n",
      "Avg loss (train): 0.0192\n",
      "Avg acc (train): 0.9434\n",
      "Avg loss (val): 0.0000\n",
      "Avg acc (val): 0.7015\n",
      "\n",
      "EPOCH NUMBER: 24\n",
      "Avg loss (train): 0.0137\n",
      "Avg acc (train): 0.9584\n",
      "Avg loss (val): 0.0001\n",
      "Avg acc (val): 0.7313\n",
      "\n",
      "EPOCH NUMBER: 25\n",
      "Avg loss (train): 0.0130\n",
      "Avg acc (train): 0.9634\n",
      "Avg loss (val): 0.0246\n",
      "Avg acc (val): 0.6716\n",
      "\n",
      "EPOCH NUMBER: 26\n",
      "Avg loss (train): 0.0168\n",
      "Avg acc (train): 0.9517\n",
      "Avg loss (val): 0.0000\n",
      "Avg acc (val): 0.6567\n",
      "\n",
      "EPOCH NUMBER: 27\n",
      "Avg loss (train): 0.0189\n",
      "Avg acc (train): 0.9418\n",
      "Avg loss (val): 0.0055\n",
      "Avg acc (val): 0.7164\n",
      "\n",
      "EPOCH NUMBER: 28\n",
      "Avg loss (train): 0.0187\n",
      "Avg acc (train): 0.9451\n",
      "Avg loss (val): 0.0000\n",
      "Avg acc (val): 0.7164\n",
      "\n",
      "EPOCH NUMBER: 29\n",
      "Avg loss (train): 0.0280\n",
      "Avg acc (train): 0.9617\n",
      "Avg loss (val): 1.1794\n",
      "Avg acc (val): 0.7612\n",
      "\n",
      "EPOCH NUMBER: 30\n",
      "Avg loss (train): 0.0263\n",
      "Avg acc (train): 0.9201\n",
      "Avg loss (val): 0.0088\n",
      "Avg acc (val): 0.7910\n",
      "\n",
      "EPOCH NUMBER: 31\n",
      "Avg loss (train): 0.0198\n",
      "Avg acc (train): 0.9418\n",
      "Avg loss (val): 0.1769\n",
      "Avg acc (val): 0.7313\n",
      "\n",
      "EPOCH NUMBER: 32\n",
      "Avg loss (train): 0.0423\n",
      "Avg acc (train): 0.9002\n",
      "Avg loss (val): 0.8315\n",
      "Avg acc (val): 0.7612\n",
      "\n",
      "EPOCH NUMBER: 33\n",
      "Avg loss (train): 0.0227\n",
      "Avg acc (train): 0.9301\n",
      "Avg loss (val): 0.0391\n",
      "Avg acc (val): 0.7612\n",
      "\n",
      "EPOCH NUMBER: 34\n",
      "Avg loss (train): 0.0140\n",
      "Avg acc (train): 0.9584\n",
      "Avg loss (val): 0.0003\n",
      "Avg acc (val): 0.6716\n",
      "\n",
      "EPOCH NUMBER: 35\n",
      "Avg loss (train): 0.0228\n",
      "Avg acc (train): 0.9301\n",
      "Avg loss (val): 0.0012\n",
      "Avg acc (val): 0.7313\n",
      "\n",
      "EPOCH NUMBER: 36\n",
      "Avg loss (train): 0.0162\n",
      "Avg acc (train): 0.9484\n",
      "Avg loss (val): 0.0001\n",
      "Avg acc (val): 0.7761\n",
      "\n",
      "EPOCH NUMBER: 37\n",
      "Avg loss (train): 0.0162\n",
      "Avg acc (train): 0.9501\n",
      "Avg loss (val): 0.0011\n",
      "Avg acc (val): 0.7313\n",
      "\n",
      "EPOCH NUMBER: 38\n",
      "Avg loss (train): 0.0145\n",
      "Avg acc (train): 0.9517\n",
      "Avg loss (val): 0.0001\n",
      "Avg acc (val): 0.7164\n",
      "\n",
      "EPOCH NUMBER: 39\n",
      "Avg loss (train): 0.0113\n",
      "Avg acc (train): 0.9667\n",
      "Avg loss (val): 0.0025\n",
      "Avg acc (val): 0.7612\n",
      "\n",
      "EPOCH NUMBER: 40\n",
      "Avg loss (train): 0.0106\n",
      "Avg acc (train): 0.9717\n",
      "Avg loss (val): 0.0148\n",
      "Avg acc (val): 0.7612\n",
      "\n",
      "EPOCH NUMBER: 41\n",
      "Avg loss (train): 0.0078\n",
      "Avg acc (train): 0.9800\n",
      "Avg loss (val): 0.0000\n",
      "Avg acc (val): 0.6866\n",
      "\n",
      "EPOCH NUMBER: 42\n",
      "Avg loss (train): 0.0084\n",
      "Avg acc (train): 0.9684\n",
      "Avg loss (val): 0.0003\n",
      "Avg acc (val): 0.7463\n",
      "\n",
      "EPOCH NUMBER: 43\n",
      "Avg loss (train): 0.0125\n",
      "Avg acc (train): 0.9651\n",
      "Avg loss (val): 0.0001\n",
      "Avg acc (val): 0.7761\n",
      "\n",
      "EPOCH NUMBER: 44\n",
      "Avg loss (train): 0.0108\n",
      "Avg acc (train): 0.9717\n",
      "Avg loss (val): 0.0151\n",
      "Avg acc (val): 0.7313\n",
      "\n",
      "EPOCH NUMBER: 45\n",
      "Avg loss (train): 0.0117\n",
      "Avg acc (train): 0.9567\n",
      "Avg loss (val): 0.0025\n",
      "Avg acc (val): 0.7463\n",
      "\n",
      "EPOCH NUMBER: 46\n",
      "Avg loss (train): 0.0110\n",
      "Avg acc (train): 0.9617\n",
      "Avg loss (val): 0.0002\n",
      "Avg acc (val): 0.7463\n",
      "\n",
      "EPOCH NUMBER: 47\n",
      "Avg loss (train): 0.0065\n",
      "Avg acc (train): 0.9817\n",
      "Avg loss (val): 0.1003\n",
      "Avg acc (val): 0.7761\n",
      "\n",
      "EPOCH NUMBER: 48\n",
      "Avg loss (train): 0.0184\n",
      "Avg acc (train): 0.9401\n",
      "Avg loss (val): 0.0002\n",
      "Avg acc (val): 0.7015\n",
      "\n",
      "EPOCH NUMBER: 49\n",
      "Avg loss (train): 0.0141\n",
      "Avg acc (train): 0.9634\n",
      "Avg loss (val): 0.0092\n",
      "Avg acc (val): 0.7612\n",
      "\n",
      "EPOCH NUMBER: 50\n",
      "Avg loss (train): 0.0084\n",
      "Avg acc (train): 0.9784\n",
      "Avg loss (val): 0.0000\n",
      "Avg acc (val): 0.7164\n",
      "\n",
      "EPOCH NUMBER: 51\n",
      "Avg loss (train): 0.0084\n",
      "Avg acc (train): 0.9800\n",
      "Avg loss (val): 0.0004\n",
      "Avg acc (val): 0.7164\n",
      "\n",
      "EPOCH NUMBER: 52\n",
      "Avg loss (train): 0.0094\n",
      "Avg acc (train): 0.9734\n",
      "Avg loss (val): 0.0000\n",
      "Avg acc (val): 0.7313\n",
      "\n",
      "EPOCH NUMBER: 53\n",
      "Avg loss (train): 0.0073\n",
      "Avg acc (train): 0.9800\n",
      "Avg loss (val): 0.0000\n",
      "Avg acc (val): 0.7612\n",
      "\n",
      "EPOCH NUMBER: 54\n",
      "Avg loss (train): 0.0083\n",
      "Avg acc (train): 0.9750\n",
      "Avg loss (val): 0.0031\n",
      "Avg acc (val): 0.7313\n",
      "\n",
      "EPOCH NUMBER: 55\n",
      "Avg loss (train): 0.0088\n",
      "Avg acc (train): 0.9750\n",
      "Avg loss (val): 0.0000\n",
      "Avg acc (val): 0.7612\n",
      "\n",
      "EPOCH NUMBER: 56\n",
      "Avg loss (train): 0.0063\n",
      "Avg acc (train): 0.9817\n",
      "Avg loss (val): 0.0016\n",
      "Avg acc (val): 0.7313\n",
      "\n",
      "EPOCH NUMBER: 57\n",
      "Avg loss (train): 0.0067\n",
      "Avg acc (train): 0.9850\n",
      "Avg loss (val): 0.0160\n",
      "Avg acc (val): 0.7761\n",
      "\n",
      "EPOCH NUMBER: 58\n",
      "Avg loss (train): 0.0100\n",
      "Avg acc (train): 0.9817\n",
      "Avg loss (val): 0.3812\n",
      "Avg acc (val): 0.7015\n",
      "\n",
      "EPOCH NUMBER: 59\n",
      "Avg loss (train): 0.0537\n",
      "Avg acc (train): 0.8669\n",
      "Avg loss (val): 0.0001\n",
      "Avg acc (val): 0.7164\n",
      "\n",
      "EPOCH NUMBER: 60\n",
      "Avg loss (train): 0.0149\n",
      "Avg acc (train): 0.9584\n",
      "Avg loss (val): 0.0005\n",
      "Avg acc (val): 0.7164\n",
      "\n",
      "EPOCH NUMBER: 61\n",
      "Avg loss (train): 0.0112\n",
      "Avg acc (train): 0.9700\n",
      "Avg loss (val): 0.0000\n",
      "Avg acc (val): 0.7164\n",
      "\n",
      "EPOCH NUMBER: 62\n",
      "Avg loss (train): 0.0104\n",
      "Avg acc (train): 0.9617\n",
      "Avg loss (val): 0.0000\n",
      "Avg acc (val): 0.7313\n",
      "\n",
      "EPOCH NUMBER: 63\n",
      "Avg loss (train): 0.0176\n",
      "Avg acc (train): 0.9667\n",
      "Avg loss (val): 0.5063\n",
      "Avg acc (val): 0.7313\n",
      "\n",
      "EPOCH NUMBER: 64\n",
      "Avg loss (train): 0.0357\n",
      "Avg acc (train): 0.8935\n",
      "Avg loss (val): 0.0023\n",
      "Avg acc (val): 0.6716\n",
      "\n",
      "EPOCH NUMBER: 65\n",
      "Avg loss (train): 0.0146\n",
      "Avg acc (train): 0.9617\n",
      "Avg loss (val): 0.2847\n",
      "Avg acc (val): 0.6269\n",
      "\n",
      "EPOCH NUMBER: 66\n",
      "Avg loss (train): 0.0226\n",
      "Avg acc (train): 0.9384\n",
      "Avg loss (val): 0.0000\n",
      "Avg acc (val): 0.7015\n",
      "\n",
      "EPOCH NUMBER: 67\n",
      "Avg loss (train): 0.0132\n",
      "Avg acc (train): 0.9667\n",
      "Avg loss (val): 0.0024\n",
      "Avg acc (val): 0.6716\n",
      "\n",
      "EPOCH NUMBER: 68\n",
      "Avg loss (train): 0.0083\n",
      "Avg acc (train): 0.9800\n",
      "Avg loss (val): 0.0282\n",
      "Avg acc (val): 0.7313\n",
      "\n",
      "EPOCH NUMBER: 69\n",
      "Avg loss (train): 0.0128\n",
      "Avg acc (train): 0.9684\n",
      "Avg loss (val): 0.1625\n",
      "Avg acc (val): 0.6567\n",
      "\n",
      "EPOCH NUMBER: 70\n",
      "Avg loss (train): 0.0208\n",
      "Avg acc (train): 0.9384\n",
      "Avg loss (val): 0.0000\n",
      "Avg acc (val): 0.7015\n",
      "\n",
      "EPOCH NUMBER: 71\n",
      "Avg loss (train): 0.0116\n",
      "Avg acc (train): 0.9750\n",
      "Avg loss (val): 0.0043\n",
      "Avg acc (val): 0.7313\n",
      "\n",
      "EPOCH NUMBER: 72\n",
      "Avg loss (train): 0.0102\n",
      "Avg acc (train): 0.9667\n",
      "Avg loss (val): 0.0006\n",
      "Avg acc (val): 0.7612\n",
      "\n",
      "EPOCH NUMBER: 73\n",
      "Avg loss (train): 0.0083\n",
      "Avg acc (train): 0.9800\n",
      "Avg loss (val): 0.0000\n",
      "Avg acc (val): 0.7910\n",
      "\n",
      "EPOCH NUMBER: 74\n",
      "Avg loss (train): 0.0084\n",
      "Avg acc (train): 0.9700\n",
      "Avg loss (val): 0.0000\n",
      "Avg acc (val): 0.8209\n",
      "\n",
      "EPOCH NUMBER: 75\n",
      "Avg loss (train): 0.0067\n",
      "Avg acc (train): 0.9817\n",
      "Avg loss (val): 0.0469\n",
      "Avg acc (val): 0.6716\n",
      "\n",
      "EPOCH NUMBER: 76\n",
      "Avg loss (train): 0.0070\n",
      "Avg acc (train): 0.9850\n",
      "Avg loss (val): 0.0000\n",
      "Avg acc (val): 0.7164\n",
      "\n",
      "EPOCH NUMBER: 77\n",
      "Avg loss (train): 0.0064\n",
      "Avg acc (train): 0.9800\n",
      "Avg loss (val): 0.0000\n",
      "Avg acc (val): 0.7164\n",
      "\n",
      "EPOCH NUMBER: 78\n",
      "Avg loss (train): 0.0059\n",
      "Avg acc (train): 0.9817\n",
      "Avg loss (val): 0.0011\n",
      "Avg acc (val): 0.7612\n",
      "\n",
      "EPOCH NUMBER: 79\n",
      "Avg loss (train): 0.0051\n",
      "Avg acc (train): 0.9900\n",
      "Avg loss (val): 0.0004\n",
      "Avg acc (val): 0.7463\n",
      "\n",
      "EPOCH NUMBER: 80\n",
      "Avg loss (train): 0.0054\n",
      "Avg acc (train): 0.9834\n",
      "Avg loss (val): 0.0014\n",
      "Avg acc (val): 0.7313\n",
      "\n",
      "EPOCH NUMBER: 81\n",
      "Avg loss (train): 0.0061\n",
      "Avg acc (train): 0.9884\n",
      "Avg loss (val): 0.1944\n",
      "Avg acc (val): 0.7612\n",
      "\n",
      "EPOCH NUMBER: 82\n",
      "Avg loss (train): 0.0282\n",
      "Avg acc (train): 0.9251\n",
      "Avg loss (val): 0.0310\n",
      "Avg acc (val): 0.7463\n",
      "\n",
      "EPOCH NUMBER: 83\n",
      "Avg loss (train): 0.0107\n",
      "Avg acc (train): 0.9700\n",
      "Avg loss (val): 0.0064\n",
      "Avg acc (val): 0.7164\n",
      "\n",
      "EPOCH NUMBER: 84\n",
      "Avg loss (train): 0.0097\n",
      "Avg acc (train): 0.9634\n",
      "Avg loss (val): 0.0321\n",
      "Avg acc (val): 0.7313\n",
      "\n",
      "EPOCH NUMBER: 85\n",
      "Avg loss (train): 0.0099\n",
      "Avg acc (train): 0.9750\n",
      "Avg loss (val): 0.0000\n",
      "Avg acc (val): 0.7761\n",
      "\n",
      "EPOCH NUMBER: 86\n",
      "Avg loss (train): 0.0061\n",
      "Avg acc (train): 0.9850\n",
      "Avg loss (val): 0.0001\n",
      "Avg acc (val): 0.7612\n",
      "\n",
      "EPOCH NUMBER: 87\n",
      "Avg loss (train): 0.0064\n",
      "Avg acc (train): 0.9800\n",
      "Avg loss (val): 0.0000\n",
      "Avg acc (val): 0.7164\n",
      "\n",
      "EPOCH NUMBER: 88\n",
      "Avg loss (train): 0.0067\n",
      "Avg acc (train): 0.9784\n",
      "Avg loss (val): 0.0000\n",
      "Avg acc (val): 0.7313\n",
      "\n",
      "EPOCH NUMBER: 89\n",
      "Avg loss (train): 0.0046\n",
      "Avg acc (train): 0.9834\n",
      "Avg loss (val): 0.0006\n",
      "Avg acc (val): 0.7164\n",
      "\n",
      "EPOCH NUMBER: 90\n",
      "Avg loss (train): 0.0044\n",
      "Avg acc (train): 0.9900\n",
      "Avg loss (val): 0.0000\n",
      "Avg acc (val): 0.6567\n",
      "\n",
      "EPOCH NUMBER: 91\n",
      "Avg loss (train): 0.0095\n",
      "Avg acc (train): 0.9684\n",
      "Avg loss (val): 0.0235\n",
      "Avg acc (val): 0.7015\n",
      "\n",
      "EPOCH NUMBER: 92\n",
      "Avg loss (train): 0.0131\n",
      "Avg acc (train): 0.9817\n",
      "Avg loss (val): 0.6019\n",
      "Avg acc (val): 0.7463\n",
      "\n",
      "EPOCH NUMBER: 93\n",
      "Avg loss (train): 0.0264\n",
      "Avg acc (train): 0.9218\n",
      "Avg loss (val): 0.0001\n",
      "Avg acc (val): 0.7612\n",
      "\n",
      "EPOCH NUMBER: 94\n",
      "Avg loss (train): 0.0106\n",
      "Avg acc (train): 0.9700\n",
      "Avg loss (val): 0.0088\n",
      "Avg acc (val): 0.7164\n",
      "\n",
      "EPOCH NUMBER: 95\n",
      "Avg loss (train): 0.0072\n",
      "Avg acc (train): 0.9817\n",
      "Avg loss (val): 0.0000\n",
      "Avg acc (val): 0.7761\n",
      "\n",
      "EPOCH NUMBER: 96\n",
      "Avg loss (train): 0.0061\n",
      "Avg acc (train): 0.9850\n",
      "Avg loss (val): 0.0001\n",
      "Avg acc (val): 0.7313\n"
     ]
    }
   ],
   "source": [
    "model_extract = Feature_Extractor()\n",
    "model_classifier = Classifier()\n",
    "\n",
    "model_extract = model_extract.to(\"cuda\")\n",
    "model_classifier = model_classifier.to(\"cuda\")\n",
    "\n",
    "params_to_update = model_classifier.parameters()\n",
    "# print(\"Params to learn:\")\n",
    "# for name,param in model_classifier.named_parameters():\n",
    "#         if param.requires_grad == True:\n",
    "#             print(\"\\t\",name)\n",
    "\n",
    "epochs = 100\n",
    "batch_sizey1 = 8\n",
    "optimizer = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "dataloader_train = DataLoader(train_set, batch_size=batch_sizey1,\n",
    "                        shuffle=True, num_workers=4)\n",
    "dataloader_val = DataLoader(val_set, batch_size=batch_sizey1,\n",
    "                        shuffle=True, num_workers=4)\n",
    "# print(\"load\")\n",
    "\n",
    "count = 0\n",
    "num_epoch_list = []\n",
    "\n",
    "accuracy_train_list = []\n",
    "loss_train_list = []\n",
    "\n",
    "accuracy_val_list = []\n",
    "loss_val_list = []\n",
    "best_acc = 0\n",
    "for j in range(epochs):\n",
    "  num_epoch_list.append(j)\n",
    "  count = 0\n",
    "  loss_train = 0\n",
    "  acc_train = 0\n",
    "  for data in dataloader_train:\n",
    "    # print(\"check\")\n",
    "    count+=1\n",
    "    batch_sizey = data['finding'].shape[0]\n",
    "    # Preprocessing the variables\n",
    "    img = data['image']\n",
    "    sex = data['sex']\n",
    "    age = data['age']\n",
    "    finding = data['finding']\n",
    "    view = data['view']\n",
    "    img = img.to(\"cuda\")\n",
    "    sex = sex.to(\"cuda\")\n",
    "    age = age.to(\"cuda\")\n",
    "    finding = finding.to(\"cuda\")\n",
    "    view = view.to(\"cuda\")\n",
    "    sex = torch.reshape(sex, (batch_sizey, 1))\n",
    "    age = torch.reshape(age, (batch_sizey, 1))\n",
    "    finding = torch.reshape(finding, (batch_sizey, 2))\n",
    "\n",
    "    # Zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    output = model_extract(img)\n",
    "    flat_output = output.view(-1, 512* 7*7)\n",
    "    x_final = torch.cat((flat_output,sex,age,view),1)\n",
    "    output_final = model_classifier(x_final)\n",
    "    find = finding.max(1, keepdim=True)[1]\n",
    "    find = torch.reshape(find,(1,batch_sizey))\n",
    "    find = find.flatten().to(\"cuda\")\n",
    "    loss = criterion(output_final,find)\n",
    "    loss.backward()               # backward pass (compute parameter updates)\n",
    "    optimizer.step()\n",
    "\n",
    "    output_final = output_final.max(1, keepdim=True)[1]\n",
    "    output_final = torch.reshape(output_final,(1,batch_sizey))\n",
    "\n",
    "    loss_train += loss.data\n",
    "    acc_train += torch.sum(output_final == find)\n",
    "\n",
    "  avg_loss = loss_train  / 601\n",
    "  avg_acc = acc_train  / 601\n",
    "  accuracy_train_list.append(avg_acc)\n",
    "  loss_train_list.append(avg_loss)\n",
    "  # For validation\n",
    "\n",
    "  count = 0\n",
    "  loss_val = 0\n",
    "  acc_val = 0\n",
    "  for data in dataloader_val:\n",
    "    count+=1\n",
    "    batch_sizey = data['finding'].shape[0]\n",
    "    # Preprocessing the variables\n",
    "    img = data['image']\n",
    "    sex = data['sex']\n",
    "    age = data['age']\n",
    "    finding = data['finding']\n",
    "    view = data['view']\n",
    "    img = img.to(\"cuda\")\n",
    "    sex = sex.to(\"cuda\")\n",
    "    age = age.to(\"cuda\")\n",
    "    finding = finding.to(\"cuda\")\n",
    "    view = view.to(\"cuda\")\n",
    "    sex = torch.reshape(sex, (batch_sizey, 1))\n",
    "    age = torch.reshape(age, (batch_sizey, 1))\n",
    "    finding = torch.reshape(finding, (batch_sizey, 2))\n",
    "\n",
    "    # Forward pass\n",
    "    output = model_extract(img)\n",
    "    flat_output = output.view(-1, 512* 7*7)\n",
    "    x_final = torch.cat((flat_output,sex,age,view),1)\n",
    "    output_final = model_classifier(x_final)\n",
    "    find = finding.max(1, keepdim=True)[1]\n",
    "    find = torch.reshape(find,(1,batch_sizey))\n",
    "    find = find.flatten().to(\"cuda\")\n",
    "\n",
    "    output_final = output_final.max(1, keepdim=True)[1]\n",
    "    output_final = torch.reshape(output_final,(1,batch_sizey))\n",
    "\n",
    "    loss_val += loss.data\n",
    "    acc_val += torch.sum(output_final == find)\n",
    "\n",
    "  print()\n",
    "  print(\"EPOCH NUMBER: %d\"%(j))\n",
    "  print(\"Avg loss (train): {:.4f}\".format(avg_loss))\n",
    "  print(\"Avg acc (train): {:.4f}\".format(avg_acc))\n",
    "\n",
    "  avg_loss = loss_val  / 67\n",
    "  avg_acc = acc_val  / 67\n",
    "  accuracy_val_list.append(avg_acc)\n",
    "  loss_val_list.append(avg_loss)\n",
    "\n",
    "  if avg_acc>best_acc:\n",
    "    print(\"saved\")\n",
    "    PATH = './no_dropout.pth'\n",
    "    torch.save(model_classifier.state_dict(), PATH)\n",
    "    best_acc = avg_acc\n",
    "  print(\"Avg loss (val): {:.4f}\".format(avg_loss))\n",
    "  print(\"Avg acc (val): {:.4f}\".format(avg_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ADHlEY65op5v"
   },
   "outputs": [],
   "source": [
    "plt.plot(num_epoch_list,accuracy_train_list, label='Train')\n",
    "plt.plot(num_epoch_list,accuracy_val_list, label='Val')\n",
    "plt.legend()\n",
    "plt.title(\"Epoch vs Accuracy\")\n",
    "plt.xlabel(\"No. of Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "plt.plot(num_epoch_list,loss_train_list, label='Train')\n",
    "plt.plot(num_epoch_list,loss_val_list, label='Val')\n",
    "plt.legend()\n",
    "plt.title(\"Epoch vs Loss\")\n",
    "plt.xlabel(\"No. of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4gF0jcFe3FLU",
    "outputId": "411e1ff8-4589-4003-86be-b58da582aa9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    }
   ],
   "source": [
    "|count = 1\n",
    "\n",
    "# for i in train_set:\n",
    "  # print(count)\n",
    "  # print(i)\n",
    "  # count+=1\n",
    "dataloader_train = DataLoader(train_set, batch_size=8,\n",
    "                        shuffle=True, num_workers=4)\n",
    "dataloader_val = DataLoader(val_set, batch_size=8,\n",
    "                        shuffle=True, num_workers=4)\n",
    "dataloader_test = DataLoader(test_set, batch_size=8,\n",
    "                        shuffle=True, num_workers=4)\n",
    "\n",
    "print(len(dataloader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VlUVnEjhdVTR",
    "outputId": "33386a10-1ccc-4ca3-e748-abdf7b5610dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0245,  1.1838,  1.4191,  1.2461,  0.0910],\n",
      "        [ 0.4712, -1.4013,  0.6251, -0.4971,  0.6933],\n",
      "        [-0.6946,  0.5746,  1.3383, -0.5251,  1.0091]], requires_grad=True)\n",
      "tensor([1, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "print(input)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print(target)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZq9WcktuJzy"
   },
   "outputs": [],
   "source": [
    "images_orig = []\n",
    "directory = './data_new/covid'\n",
    "for filename in os.listdir(directory):\n",
    "    # if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        images_orig.append([filename,0])\n",
    "\n",
    "directory = './data_new/not_covid'\n",
    "for filename in os.listdir(directory):\n",
    "    # if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        images_orig.append([filename,1])\n",
    "print(images_orig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m-6anPGDwYmk",
    "outputId": "e69d551d-49fd-480e-aa93-178cb2e5859b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676 84 86 846\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "images_orig = np.asarray(images_orig)\n",
    "np.random.shuffle(images_orig)\n",
    "total_len = images_orig.shape[0]\n",
    "train_size = int(0.8*total_len)\n",
    "val_size = int(0.1*total_len)\n",
    "test_size = total_len - train_size - val_size\n",
    "\n",
    "print(train_size,val_size,test_size,total_len)\n",
    "\n",
    "for i in range(train_size):\n",
    "  # print(images_orig[i])\n",
    "  if images_orig[i,1] == '0':\n",
    "    shutil.copyfile('./data_new/covid/'+images_orig[i,0], './data_new/train/covid/'+images_orig[i,0])\n",
    "  else:\n",
    "    shutil.copyfile('./data_new/not_covid/'+images_orig[i,0], './data_new/train/not_covid/'+images_orig[i,0])\n",
    "\n",
    "for i in range(train_size,train_size+val_size):\n",
    "  if images_orig[i,1] == '0':\n",
    "    shutil.copyfile('./data_new/covid/'+images_orig[i,0], './data_new/val/covid/'+images_orig[i,0])\n",
    "  else:\n",
    "    shutil.copyfile('./data_new/not_covid/'+images_orig[i,0], './data_new/val/not_covid/'+images_orig[i,0])\n",
    "\n",
    "for i in range(train_size+val_size,train_size+val_size+test_size):\n",
    "  if images_orig[i,1] == '0':\n",
    "    shutil.copyfile('./data_new/covid/'+images_orig[i,0], './data_new/test/covid/'+images_orig[i,0])\n",
    "  else:\n",
    "    shutil.copyfile('./data_new/not_covid/'+images_orig[i,0], './data_new/test/not_covid/'+images_orig[i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F5C4KLLIo4jR",
    "outputId": "270a6d33-e2dd-4022-b65a-95ef34e55900"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 676 images under train\n",
      "Loaded 84 images under val\n",
      "Loaded 86 images under test\n",
      "Classes: \n",
      "['covid', 'not_covid']\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data_new'\n",
    "TRAIN = 'train'\n",
    "VAL = 'val'\n",
    "TEST = 'test'\n",
    "\n",
    "# VGG-16 Takes 224x224 images as input, so we resize all of them\n",
    "data_transforms = {\n",
    "    TRAIN: transforms.Compose([\n",
    "        # Data augmentation is a good practice for the train set\n",
    "        # Here, we randomly crop the image to 224x224 and\n",
    "        # randomly flip it horizontally. \n",
    "        transforms.RandomResizedCrop(224),\n",
    "        torchvision.transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.RandomRotation(20, resample=PIL.Image.BILINEAR),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    VAL: transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    TEST: transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(\n",
    "        os.path.join(data_dir, x), \n",
    "        transform=data_transforms[x]\n",
    "    )\n",
    "    for x in [TRAIN, VAL, TEST]\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(\n",
    "        image_datasets[x], batch_size=8,\n",
    "        shuffle=True, num_workers=4\n",
    "    )\n",
    "    for x in [TRAIN, VAL, TEST]\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN, VAL, TEST]}\n",
    "\n",
    "for x in [TRAIN, VAL, TEST]:\n",
    "    print(\"Loaded {} images under {}\".format(dataset_sizes[x], x))\n",
    "    \n",
    "print(\"Classes: \")\n",
    "class_names = image_datasets[TRAIN].classes\n",
    "print(image_datasets[TRAIN].classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lk-5FLEZpKpG",
    "outputId": "d778a8f5-09d8-438a-fee7-b4ee9d504fdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': tensor([[[[0.0000, 0.0027, 0.0078,  ..., 0.1895, 0.2152, 0.2344],\n",
      "          [0.0189, 0.0196, 0.0228,  ..., 0.1647, 0.1890, 0.2074],\n",
      "          [0.0275, 0.0314, 0.0353,  ..., 0.1747, 0.1747, 0.1871],\n",
      "          ...,\n",
      "          [0.7765, 0.7744, 0.7701,  ..., 0.7255, 0.7333, 0.7373],\n",
      "          [0.7765, 0.7765, 0.7703,  ..., 0.7324, 0.7333, 0.7373],\n",
      "          [0.7736, 0.7743, 0.7765,  ..., 0.7265, 0.7355, 0.7451]],\n",
      "\n",
      "         [[0.0000, 0.0027, 0.0078,  ..., 0.1895, 0.2152, 0.2344],\n",
      "          [0.0189, 0.0196, 0.0228,  ..., 0.1647, 0.1890, 0.2074],\n",
      "          [0.0275, 0.0314, 0.0353,  ..., 0.1747, 0.1747, 0.1871],\n",
      "          ...,\n",
      "          [0.7765, 0.7744, 0.7701,  ..., 0.7255, 0.7333, 0.7373],\n",
      "          [0.7765, 0.7765, 0.7703,  ..., 0.7324, 0.7333, 0.7373],\n",
      "          [0.7736, 0.7743, 0.7765,  ..., 0.7265, 0.7355, 0.7451]],\n",
      "\n",
      "         [[0.0000, 0.0027, 0.0078,  ..., 0.1895, 0.2152, 0.2344],\n",
      "          [0.0189, 0.0196, 0.0228,  ..., 0.1647, 0.1890, 0.2074],\n",
      "          [0.0275, 0.0314, 0.0353,  ..., 0.1747, 0.1747, 0.1871],\n",
      "          ...,\n",
      "          [0.7765, 0.7744, 0.7701,  ..., 0.7255, 0.7333, 0.7373],\n",
      "          [0.7765, 0.7765, 0.7703,  ..., 0.7324, 0.7333, 0.7373],\n",
      "          [0.7736, 0.7743, 0.7765,  ..., 0.7265, 0.7355, 0.7451]]],\n",
      "\n",
      "\n",
      "        [[[0.8003, 0.8103, 0.8300,  ..., 0.8510, 0.8510, 0.8495],\n",
      "          [0.8380, 0.8447, 0.8615,  ..., 0.8353, 0.8362, 0.8353],\n",
      "          [0.8350, 0.8456, 0.8695,  ..., 0.8311, 0.8227, 0.8392],\n",
      "          ...,\n",
      "          [0.1636, 0.1465, 0.1382,  ..., 0.1464, 0.1812, 0.1884],\n",
      "          [0.1697, 0.1608, 0.1520,  ..., 0.1450, 0.1514, 0.1389],\n",
      "          [0.1522, 0.1375, 0.1368,  ..., 0.1371, 0.1370, 0.1406]],\n",
      "\n",
      "         [[0.8003, 0.8103, 0.8300,  ..., 0.8510, 0.8510, 0.8495],\n",
      "          [0.8380, 0.8447, 0.8615,  ..., 0.8353, 0.8362, 0.8353],\n",
      "          [0.8350, 0.8456, 0.8695,  ..., 0.8311, 0.8227, 0.8392],\n",
      "          ...,\n",
      "          [0.1636, 0.1465, 0.1382,  ..., 0.1464, 0.1812, 0.1884],\n",
      "          [0.1697, 0.1608, 0.1520,  ..., 0.1450, 0.1514, 0.1389],\n",
      "          [0.1522, 0.1375, 0.1368,  ..., 0.1371, 0.1370, 0.1406]],\n",
      "\n",
      "         [[0.8003, 0.8103, 0.8300,  ..., 0.8510, 0.8510, 0.8495],\n",
      "          [0.8380, 0.8447, 0.8615,  ..., 0.8353, 0.8362, 0.8353],\n",
      "          [0.8350, 0.8456, 0.8695,  ..., 0.8311, 0.8227, 0.8392],\n",
      "          ...,\n",
      "          [0.1636, 0.1465, 0.1382,  ..., 0.1464, 0.1812, 0.1884],\n",
      "          [0.1697, 0.1608, 0.1520,  ..., 0.1450, 0.1514, 0.1389],\n",
      "          [0.1522, 0.1375, 0.1368,  ..., 0.1371, 0.1370, 0.1406]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0019,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0074,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0160,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0019,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0074,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0160,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0019,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0074,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0160,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0216, 0.0293, 0.0347,  ..., 0.0118, 0.0118, 0.0118],\n",
      "          [0.0145, 0.0229, 0.0283,  ..., 0.0118, 0.0118, 0.0118],\n",
      "          [0.0136, 0.0185, 0.0238,  ..., 0.0118, 0.0118, 0.0118],\n",
      "          ...,\n",
      "          [0.5777, 0.5777, 0.5729,  ..., 0.3651, 0.3460, 0.3260],\n",
      "          [0.5751, 0.5732, 0.5651,  ..., 0.3666, 0.3471, 0.3260],\n",
      "          [0.5711, 0.5691, 0.5641,  ..., 0.3659, 0.3465, 0.3268]],\n",
      "\n",
      "         [[0.0216, 0.0293, 0.0347,  ..., 0.0118, 0.0118, 0.0118],\n",
      "          [0.0145, 0.0229, 0.0283,  ..., 0.0118, 0.0118, 0.0118],\n",
      "          [0.0136, 0.0185, 0.0238,  ..., 0.0118, 0.0118, 0.0118],\n",
      "          ...,\n",
      "          [0.5777, 0.5777, 0.5729,  ..., 0.3651, 0.3460, 0.3260],\n",
      "          [0.5751, 0.5732, 0.5651,  ..., 0.3666, 0.3471, 0.3260],\n",
      "          [0.5711, 0.5691, 0.5641,  ..., 0.3659, 0.3465, 0.3268]],\n",
      "\n",
      "         [[0.0216, 0.0293, 0.0347,  ..., 0.0118, 0.0118, 0.0118],\n",
      "          [0.0145, 0.0229, 0.0283,  ..., 0.0118, 0.0118, 0.0118],\n",
      "          [0.0136, 0.0185, 0.0238,  ..., 0.0118, 0.0118, 0.0118],\n",
      "          ...,\n",
      "          [0.5777, 0.5777, 0.5729,  ..., 0.3651, 0.3460, 0.3260],\n",
      "          [0.5751, 0.5732, 0.5651,  ..., 0.3666, 0.3471, 0.3260],\n",
      "          [0.5711, 0.5691, 0.5641,  ..., 0.3659, 0.3465, 0.3268]]],\n",
      "\n",
      "\n",
      "        [[[0.0863, 0.0745, 0.0785,  ..., 0.0431, 0.0412, 0.0392],\n",
      "          [0.0863, 0.0823, 0.0824,  ..., 0.0706, 0.0588, 0.0470],\n",
      "          [0.0941, 0.0784, 0.0746,  ..., 0.0726, 0.0667, 0.0686],\n",
      "          ...,\n",
      "          [0.2314, 0.2392, 0.2432,  ..., 0.4922, 0.5020, 0.4843],\n",
      "          [0.2157, 0.2392, 0.2432,  ..., 0.5059, 0.4843, 0.4824],\n",
      "          [0.1804, 0.2118, 0.2316,  ..., 0.4804, 0.4784, 0.4745]],\n",
      "\n",
      "         [[0.2196, 0.2078, 0.2039,  ..., 0.1373, 0.1255, 0.1137],\n",
      "          [0.2157, 0.2118, 0.2078,  ..., 0.1647, 0.1470, 0.1254],\n",
      "          [0.2118, 0.1960, 0.1922,  ..., 0.1667, 0.1608, 0.1627],\n",
      "          ...,\n",
      "          [0.4824, 0.4902, 0.5022,  ..., 0.8216, 0.8353, 0.8176],\n",
      "          [0.4589, 0.4824, 0.4943,  ..., 0.8353, 0.8157, 0.8235],\n",
      "          [0.3883, 0.4511, 0.4786,  ..., 0.8098, 0.8098, 0.8157]],\n",
      "\n",
      "         [[0.2431, 0.2314, 0.2275,  ..., 0.1471, 0.1372, 0.1294],\n",
      "          [0.2392, 0.2353, 0.2275,  ..., 0.1882, 0.1725, 0.1529],\n",
      "          [0.2392, 0.2235, 0.2157,  ..., 0.1902, 0.1843, 0.1862],\n",
      "          ...,\n",
      "          [0.5294, 0.5451, 0.5610,  ..., 0.8922, 0.9059, 0.8863],\n",
      "          [0.4981, 0.5373, 0.5531,  ..., 0.9059, 0.8843, 0.8863],\n",
      "          [0.4315, 0.4982, 0.5335,  ..., 0.8804, 0.8784, 0.8784]]],\n",
      "\n",
      "\n",
      "        [[[0.4471, 0.4637, 0.5334,  ..., 0.3922, 0.3961, 0.3961],\n",
      "          [0.4712, 0.5238, 0.5977,  ..., 0.4617, 0.4820, 0.4899],\n",
      "          [0.6238, 0.6435, 0.6340,  ..., 0.4343, 0.4706, 0.4706],\n",
      "          ...,\n",
      "          [0.7569, 0.7608, 0.7654,  ..., 0.5572, 0.5304, 0.5101],\n",
      "          [0.7412, 0.7454, 0.7572,  ..., 0.5501, 0.5487, 0.5180],\n",
      "          [0.7297, 0.7415, 0.7490,  ..., 0.5704, 0.5415, 0.5373]],\n",
      "\n",
      "         [[0.4471, 0.4637, 0.5334,  ..., 0.3922, 0.3961, 0.3961],\n",
      "          [0.4712, 0.5238, 0.5977,  ..., 0.4617, 0.4820, 0.4899],\n",
      "          [0.6238, 0.6435, 0.6340,  ..., 0.4343, 0.4706, 0.4706],\n",
      "          ...,\n",
      "          [0.7569, 0.7608, 0.7654,  ..., 0.5572, 0.5304, 0.5101],\n",
      "          [0.7412, 0.7454, 0.7572,  ..., 0.5501, 0.5487, 0.5180],\n",
      "          [0.7297, 0.7415, 0.7490,  ..., 0.5704, 0.5415, 0.5373]],\n",
      "\n",
      "         [[0.4471, 0.4637, 0.5334,  ..., 0.3922, 0.3961, 0.3961],\n",
      "          [0.4712, 0.5238, 0.5977,  ..., 0.4617, 0.4820, 0.4899],\n",
      "          [0.6238, 0.6435, 0.6340,  ..., 0.4343, 0.4706, 0.4706],\n",
      "          ...,\n",
      "          [0.7569, 0.7608, 0.7654,  ..., 0.5572, 0.5304, 0.5101],\n",
      "          [0.7412, 0.7454, 0.7572,  ..., 0.5501, 0.5487, 0.5180],\n",
      "          [0.7297, 0.7415, 0.7490,  ..., 0.5704, 0.5415, 0.5373]]]],\n",
      "       dtype=torch.float64), 'sex': tensor([0, 0, 0, 0, 0, 1, 1, 0]), 'age': tensor([0.5500, 0.2200, 0.4000, 0.4500, 0.7500, 0.7100, 0.2100, 0.5000],\n",
      "       dtype=torch.float64), 'finding': tensor([0, 0, 1, 1, 1, 1, 1, 1]), 'view': tensor([[1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "def imshow(inp, title=None):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    # plt.figure(figsize=(10, 10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)\n",
    "\n",
    "def show_databatch(inputs, classes):\n",
    "    out = torchvision.utils.make_grid(inputs)\n",
    "    imshow(out, title=[class_names[x] for x in classes])\n",
    "\n",
    "# Get a batch of training data\n",
    "# inputs, sex, age, finding, view = next(iter(dataloader_test))\n",
    "# show_databatch(inputs, finding)\n",
    "# testie = next(iter(dataloader_test))\n",
    "# print(testie)\n",
    "print(next(iter(dataloader_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wIoTq6Gqpcp7"
   },
   "outputs": [],
   "source": [
    "def visualize_model(vgg, num_images=6):\n",
    "    was_training = vgg.training\n",
    "    \n",
    "    # Set model for evaluation\n",
    "    vgg.train(False)\n",
    "    vgg.eval() \n",
    "    \n",
    "    images_so_far = 0\n",
    "\n",
    "    for i, data in enumerate(dataloaders[TEST]):\n",
    "        inputs, labels = data\n",
    "        size = inputs.size()[0]\n",
    "        \n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
    "        \n",
    "        outputs = vgg(inputs)\n",
    "        \n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        predicted_labels = [preds[j] for j in range(inputs.size()[0])]\n",
    "        \n",
    "        print(\"Ground truth:\")\n",
    "        show_databatch(inputs.data.cpu(), labels.data.cpu())\n",
    "        print(\"Prediction:\")\n",
    "        show_databatch(inputs.data.cpu(), predicted_labels)\n",
    "        \n",
    "        del inputs, labels, outputs, preds, predicted_labels\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        images_so_far += size\n",
    "        if images_so_far >= num_images:\n",
    "            break\n",
    "        \n",
    "    vgg.train(mode=was_training) # Revert model back to original training state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16HnJOzVppZK"
   },
   "outputs": [],
   "source": [
    "def eval_model(vgg, criterion):\n",
    "    since = time.time()\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    loss_test = 0\n",
    "    acc_test = 0\n",
    "    \n",
    "    test_batches = len(dataloader_test)\n",
    "    print(\"Evaluating model\")\n",
    "    print('-' * 10)\n",
    "    \n",
    "    final_classes = []\n",
    "    yhat_classes = []\n",
    "    for i, data in enumerate(dataloader_test):\n",
    "        # print(i,data[1])\n",
    "        # print(data)\n",
    "        for ii in data['finding']:\n",
    "          final_classes.append(int(ii))\n",
    "        if i % 100 == 0:\n",
    "            print(\"\\rTest batch {}/{}\".format(i, test_batches), end='', flush=True)\n",
    "\n",
    "        vgg.train(False)\n",
    "        vgg.eval()\n",
    "        inputs = data['image']\n",
    "        sex = data['sex']\n",
    "        age = data['age']\n",
    "        finding = data['finding']\n",
    "        view = data['view']\n",
    "\n",
    "        if use_gpu:\n",
    "            inputs, finding = Variable(inputs.cuda(), volatile=True), Variable(finding.cuda(), volatile=True)\n",
    "        else:\n",
    "            inputs, finding = Variable(inputs, volatile=True), Variable(finding, volatile=True)\n",
    "\n",
    "        outputs = vgg(inputs)\n",
    "        # print(\"original\")\n",
    "        # print(final_classes)\n",
    "        # print(outputs)\n",
    "        # preds = np.argmax(np.asarray(outputs),axis=1)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        # print(preds)\n",
    "        for ii in preds:\n",
    "          yhat_classes.append(int(ii))\n",
    "\n",
    "        loss = criterion(outputs, finding)\n",
    "\n",
    "        loss_test += loss.data\n",
    "        acc_test += torch.sum(preds == finding)\n",
    "\n",
    "        del inputs, finding, outputs, preds\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    avg_loss = loss_test / test_batches\n",
    "    avg_acc = acc_test / test_batches\n",
    "    print(len(final_classes),len(yhat_classes))\n",
    "    elapsed_time = time.time() - since\n",
    "    print()\n",
    "    print(\"Evaluation completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
    "    print(\"Avg loss (test): {:.4f}\".format(avg_loss))\n",
    "    print(\"Avg acc (test): {:.4f}\".format(avg_acc))\n",
    "    print('-' * 10)\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = accuracy_score(final_classes, yhat_classes)\n",
    "    print('Accuracy (test): %f' % accuracy)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(final_classes, yhat_classes)\n",
    "    print('Precision (test): %f' % precision)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(final_classes, yhat_classes)\n",
    "    print('Recall (test): %f' % recall)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(final_classes, yhat_classes)\n",
    "    print('F1 score (test): %f' % f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aXyyXWL1pynN",
    "outputId": "5c9aec1a-8ba3-4680-8656-b88dcfa2e057"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "25088\n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "checkie\n"
     ]
    }
   ],
   "source": [
    "# Load the pretrained model from pytorch\n",
    "vgg16 = models.vgg16_bn()\n",
    "vgg16.load_state_dict(torch.load(\"/root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\", map_location=\"cuda:0\"))\n",
    "print(vgg16.classifier[6].out_features) # 1000 \n",
    "\n",
    "\n",
    "# Freeze training for all layers\n",
    "for param in vgg16.features.parameters():\n",
    "    param.require_grad = False\n",
    "\n",
    "# Newly created modules have require_grad=True by default\n",
    "# print(vgg16.features[43].out_features)\n",
    "num_features = vgg16.classifier[6].in_features\n",
    "num_features1 = vgg16.classifier[0].in_features\n",
    "print(num_features1)\n",
    "features = list(vgg16.classifier.children())[:-1] # Remove last layer\n",
    "features.extend([nn.Linear(num_features,2)]) # Add our layer with 2 outputs\n",
    "vgg16.classifier = nn.Sequential(*features) # Replace the model classifier\n",
    "print(vgg16)\n",
    "\n",
    "if use_gpu:\n",
    "    print(\"checkie\")\n",
    "    vgg16.cuda() #.cuda() will move everything to the GPU side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kE5MuVAki6tc",
    "outputId": "96c97aaa-33a7-4c65-dbae-63f7c2570c06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vgg_added_features(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (poolie): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25096, out_features=4096, bias=True)\n",
      "    (1): Sequential(\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model_ft = models.vgg16(pretrained=True)\n",
    "\n",
    "# for param in model_ft.parameters():\n",
    "    # param.requires_grad = False\n",
    "\n",
    "class Vgg_added_features(nn.Module):\n",
    "    def __init__(self, originalModel):\n",
    "        super(Vgg_added_features, self).__init__()\n",
    "        self.features = nn.Sequential(*list(originalModel.features))\n",
    "        self.poolie = originalModel.avgpool.cuda()\n",
    "        self.classifier = nn.Sequential(nn.Linear(25096, 4096),originalModel.classifier[1:]).cuda()\n",
    "        # self.classifier = nn.Sequential(originalModel.classifier[0:])\n",
    "        #self.avg_pool = nn.AdaptiveAvgPool2d((7,7))\n",
    "    \n",
    "    def forward(self, x, x_cat):\n",
    "        # print(\"INPUT SHAPE\")\n",
    "        # print(x.shape)\n",
    "        x = self.features(x)\n",
    "        # print(\"VGG16\")\n",
    "        # print(x)\n",
    "        # print(x.shape)\n",
    "        x = self.poolie(x)\n",
    "        # print(\"MAXPOOL\")\n",
    "        # print(x.shape)\n",
    "        # print(x)\n",
    "\n",
    "        x= torch.reshape(x,(8,25088))\n",
    "\n",
    "        # print(\"AFTER RESHAPING\")\n",
    "        # print(x.shape)\n",
    "        # print(x_cat.shape)\n",
    "\n",
    "        x_final = torch.cat((x,x_cat),1)\n",
    "        # print(\"CHECK\")\n",
    "        x_final = torch.tensor(x_final).cuda()\n",
    "        # x_final = Variable(x_final.cuda()),\n",
    "        # x_final = torch.from_numpy(x_final)\n",
    "        x_final = torch.tensor(self.classifier(x_final)).cuda()\n",
    "\n",
    "        # x = torch.mul(torch.sign(x),torch.sqrt(torch.abs(x)+1e-12))\n",
    "        # print(x.shape)\n",
    "        # x = F.normalize(x, p=2, dim=1)\n",
    "        # print(x.shape)\n",
    "        # x = self.classifier(x)\n",
    "        # print(x.shape)\n",
    "        return x_final\n",
    "\n",
    "model = Vgg_added_features(vgg16)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EiN0NP9Gre6e"
   },
   "outputs": [],
   "source": [
    "def train_model(m_vgg, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(vgg16.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    avg_loss_val = 0\n",
    "    avg_acc_val = 0\n",
    "    \n",
    "    train_batches = len(dataloader_train)\n",
    "    val_batches = len(dataloader_val)\n",
    "    test_batches = len(dataloader_test)\n",
    "    print(train_batches,val_batches,test_batches)\n",
    "\n",
    "    num_epoch_list = []\n",
    "\n",
    "    accuracy_test_list = []\n",
    "    loss_test_list = []\n",
    "\n",
    "    accuracy_train_list = []\n",
    "    loss_train_list = []\n",
    "\n",
    "    accuracy_val_list = []\n",
    "    loss_val_list = []\n",
    "    for epoch in range(num_epochs):\n",
    "        num_epoch_list.append(int(epoch))\n",
    "        print(\"Epoch {}/{}\".format(epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        loss_train = 0\n",
    "        loss_val = 0\n",
    "        loss_test = 0\n",
    "        acc_train = 0\n",
    "        acc_val = 0\n",
    "        acc_test = 0\n",
    "        \n",
    "        m_vgg.train(True)\n",
    "        count=1\n",
    "        for i, data in enumerate(dataloader_train):\n",
    "            # print(count)\n",
    "            # count+=1\n",
    "            if i % 100 == 0:\n",
    "                print(\"\\rTraining batch {}/{}\".format(i, train_batches / 2), end='', flush=True)\n",
    "                \n",
    "            # Use half training dataset\n",
    "            if i >= train_batches / 2:\n",
    "                break\n",
    "                \n",
    "            # inputs, labels = data\n",
    "            inputs = data['image']\n",
    "            sex = data['sex']\n",
    "            age = data['age']\n",
    "            finding = data['finding']\n",
    "            view = data['view']\n",
    "            # finding = tf.cast(finding, tf.float64)\n",
    "            finding = finding.float()\n",
    "            sex = torch.reshape(sex, (8, 1))\n",
    "            age = torch.reshape(age, (8, 1))\n",
    "            final_cat = torch.cat((sex, age), 1)\n",
    "            final_cat1 = torch.cat((final_cat,view),1)\n",
    "            if 1:\n",
    "                # print(\"check\")\n",
    "                inputs, finding,final_cat1 = Variable(inputs.cuda(),requires_grad=True), Variable(finding.cuda(),requires_grad=True), Variable(final_cat1.cuda(),requires_grad=True)\n",
    "            else:\n",
    "                inputs, finding,final_cat1 = Variable(inputs,requires_grad=True), Variable(finding,requires_grad=True), Variable(final_cat1,requires_grad=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = m_vgg(inputs,final_cat1)\n",
    "            # print(\"OUTPUTS OF VGG\")\n",
    "            # print(outputs.shape)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            # finding = tf.cast(finding, tf.int32)\n",
    "            finding = finding.long()\n",
    "            loss = criterion(outputs, finding)\n",
    "            print(\"done\")\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_train += loss.data\n",
    "            acc_train += torch.sum(preds == finding)\n",
    "            # print(\"THE accuracy at each step\")\n",
    "            # print(torch.sum(preds == finding))\n",
    "            del inputs, finding, outputs, preds\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        print()\n",
    "        # * 2 as we only used half of the dataset\n",
    "        avg_loss = loss_train * 2 / (train_batches*8)\n",
    "        avg_acc = acc_train * 2 / (train_batches*8)\n",
    "        \n",
    "        # For validation\n",
    "\n",
    "        m_vgg.train(False)\n",
    "        m_vgg.eval()\n",
    "        count = 0\n",
    "        for i, data in enumerate(dataloader_val):\n",
    "            # count+=1\n",
    "            # print(count)\n",
    "            if i % 100 == 0:\n",
    "                print(\"\\rValidation batch {}/{}\".format(i, val_batches), end='', flush=True)\n",
    "            if i >= 15:\n",
    "                break   \n",
    "            inputs = data['image']\n",
    "            sex = data['sex']\n",
    "            age = data['age']\n",
    "            finding = data['finding']\n",
    "            # finding = tf.cast(finding, tf.float64)\n",
    "            finding = finding.float()\n",
    "            view = data['view']\n",
    "            \n",
    "            sex = torch.reshape(sex, (8, 1))\n",
    "            age = torch.reshape(age, (8, 1))\n",
    "            final_cat = torch.cat((sex, age), 1)\n",
    "            final_cat1 = torch.cat((final_cat,view),1)\n",
    "            if 1:\n",
    "                # print(\"check\")\n",
    "                inputs, finding,final_cat1 = Variable(inputs.cuda(),requires_grad=True), Variable(finding.cuda(),requires_grad=True), Variable(final_cat1.cuda(),requires_grad=True)\n",
    "            else:\n",
    "                inputs, finding,final_cat1 = Variable(inputs,requires_grad=True), Variable(finding,requires_grad=True), Variable(final_cat1,requires_grad=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = m_vgg(inputs,final_cat1)\n",
    "            \n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            finding = finding.long()\n",
    "            loss = criterion(outputs, finding)\n",
    "            \n",
    "            loss_val += loss.data\n",
    "            acc_val += torch.sum(preds == finding)\n",
    "            \n",
    "            del inputs, finding, outputs, preds\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        avg_loss_val = loss_val / 67\n",
    "        avg_acc_val = acc_val / 67\n",
    "\n",
    "        # For test\n",
    "        m_vgg.train(False)\n",
    "        m_vgg.eval()\n",
    "        count=0   \n",
    "        for i, data in enumerate(dataloader_test):\n",
    "            # count+=1\n",
    "            # print(count)\n",
    "            if i % 100 == 0:\n",
    "                print(\"\\rTest batch {}/{}\".format(i, test_batches), end='', flush=True)\n",
    "            # if i >= 15:\n",
    "            #     break    \n",
    "            inputs = data['image']\n",
    "            sex = data['sex']\n",
    "            age = data['age']\n",
    "            finding = data['finding']\n",
    "            view = data['view']\n",
    "            # finding = tf.cast(finding, tf.float64)\n",
    "            finding = finding.float()\n",
    "            sex = torch.reshape(sex, (8, 1))\n",
    "            age = torch.reshape(age, (8, 1))\n",
    "            final_cat = torch.cat((sex, age), 1)\n",
    "            final_cat1 = torch.cat((final_cat,view),1)\n",
    "            if 1:\n",
    "                # print(\"check\")\n",
    "                inputs, finding,final_cat1 = Variable(inputs.cuda(),requires_grad=True), Variable(finding.cuda(),requires_grad=True), Variable(final_cat1.cuda(),requires_grad=True)\n",
    "            else:\n",
    "                inputs, finding,final_cat1 = Variable(inputs,requires_grad=True), Variable(finding,requires_grad=True), Variable(final_cat1,requires_grad=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = m_vgg(inputs)\n",
    "            \n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            finding = tf.cast(finding, tf.float64)\n",
    "            finding = finding.long()\n",
    "            loss = criterion(outputs, finding)\n",
    "            print(\"done\")\n",
    "            \n",
    "            loss_test += loss.data\n",
    "            acc_test += torch.sum(preds == finding)\n",
    "            \n",
    "            del inputs, finding, outputs, preds\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        avg_loss_test = loss_test/ 66\n",
    "        avg_acc_test = acc_test / 66\n",
    "        \n",
    "        print()\n",
    "        print(\"Epoch {} result: \".format(epoch))\n",
    "        print(\"Avg loss (train): {:.4f}\".format(avg_loss))\n",
    "        print(\"Avg acc (train): {:.4f}\".format(avg_acc))\n",
    "        accuracy_train_list.append(avg_acc)\n",
    "        loss_train_list.append(avg_loss)\n",
    "        print(\"Avg loss (val): {:.4f}\".format(avg_loss_val))\n",
    "        print(\"Avg acc (val): {:.4f}\".format(avg_acc_val))\n",
    "        accuracy_val_list.append(avg_acc_val)\n",
    "        loss_val_list.append(avg_loss_val)\n",
    "        print(\"Avg loss (test): {:.4f}\".format(avg_loss_test))\n",
    "        print(\"Avg acc (test): {:.4f}\".format(avg_acc_test))\n",
    "        accuracy_test_list.append(avg_acc_test)\n",
    "        loss_test_list.append(avg_loss_test)\n",
    "        print('-' * 10)\n",
    "        print()\n",
    "        \n",
    "        if avg_acc_val > best_acc:\n",
    "            best_acc = avg_acc_val\n",
    "            best_model_wts = copy.deepcopy(vgg.state_dict())\n",
    "        \n",
    "    elapsed_time = time.time() - since\n",
    "    print()\n",
    "    print(\"Training completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
    "    print(\"Best acc: {:.4f}\".format(best_acc))\n",
    "    \n",
    "    vgg.load_state_dict(best_model_wts)\n",
    "    return vgg, accuracy_test_list, loss_test_list, accuracy_train_list, loss_train_list,accuracy_val_list, loss_val_list,num_epoch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "drz5KD4JdaxS",
    "outputId": "aeb8f945-56eb-4c77-c382-d1f34e3deb6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkie\n"
     ]
    }
   ],
   "source": [
    "modified_vgg = Vgg_added_features(vgg16)\n",
    "if use_gpu:\n",
    "    print(\"checkie\")\n",
    "    modified_vgg.cuda()\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "X3jm-e2lyw_r",
    "outputId": "9073c028-6cef-4b77-c70b-21afbcf314d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 9 9\n",
      "Epoch 0/1\n",
      "----------\n",
      "Training batch 0/33.5done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-d2939f2dbb9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodified_vgg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVgg_added_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvgg16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodified_vgg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-97eecc8bc1bb>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(m_vgg, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "modified_vgg = Vgg_added_features(vgg16)\n",
    "vgg16, accuracy_test, loss_test, accuracy_train, loss_train,accuracy_val, loss_val,num_epoch = train_model(modified_vgg, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "id": "EkloAaVbp1uJ",
    "outputId": "ee16ac69-9581-4aa3-962c-ac9dcbed00b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model..\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-17f1e601f100>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresume_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading pretrained model..\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mvgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./VGG16_v2-OCT_Retina_half_dataset.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loaded!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vgg16' is not defined"
     ]
    }
   ],
   "source": [
    "# If you want to train the model for more than 2 epochs, set this to True after the first run\n",
    "resume_training = False\n",
    "\n",
    "if resume_training:\n",
    "    print(\"Loading pretrained model..\")\n",
    "    vgg16.load_state_dict(torch.load('./VGG16_v2-OCT_Retina_half_dataset.pt'))\n",
    "    print(\"Loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dr2e7_IpqpSl"
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    vgg16.cuda() #.cuda() will move everything to the GPU side\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "vgg16, accuracy_test, loss_test, accuracy_train, loss_train,accuracy_val, loss_val,num_epoch = train_model(vgg16, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m10sg1oEqphW",
    "outputId": "7f581186-fb3a-4b3c-d68c-2f6cdf32ca53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test before training\n",
      "Evaluating model\n",
      "----------\n",
      "Test batch 0/9"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 66\n",
      "\n",
      "Evaluation completed in 1m 7s\n",
      "Avg loss (test): 0.6844\n",
      "Avg acc (test): 3.3333\n",
      "----------\n",
      "Accuracy (test): 0.454545\n",
      "Precision (test): 0.395349\n",
      "Recall (test): 0.629630\n",
      "F1 score (test): 0.485714\n"
     ]
    }
   ],
   "source": [
    "print(\"Test before training\")\n",
    "eval_model(vgg16, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0GzBnXdhaWl8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fu1234peq2yI"
   },
   "outputs": [],
   "source": [
    "def train_model(vgg, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(vgg.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    avg_loss_val = 0\n",
    "    avg_acc_val = 0\n",
    "    \n",
    "    train_batches = len(dataloaders[TRAIN])\n",
    "    val_batches = len(dataloaders[VAL])\n",
    "    test_batches = len(dataloaders[TEST])\n",
    "\n",
    "    num_epoch_list = []\n",
    "\n",
    "    accuracy_test_list = []\n",
    "    loss_test_list = []\n",
    "\n",
    "    accuracy_train_list = []\n",
    "    loss_train_list = []\n",
    "\n",
    "    accuracy_val_list = []\n",
    "    loss_val_list = []\n",
    "    for epoch in range(num_epochs):\n",
    "        num_epoch_list.append(int(epoch))\n",
    "        print(\"Epoch {}/{}\".format(epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        loss_train = 0\n",
    "        loss_val = 0\n",
    "        loss_test = 0\n",
    "        acc_train = 0\n",
    "        acc_val = 0\n",
    "        acc_test = 0\n",
    "        \n",
    "        vgg.train(True)\n",
    "        \n",
    "        for i, data in enumerate(dataloaders[TRAIN]):\n",
    "            if i % 100 == 0:\n",
    "                print(\"\\rTraining batch {}/{}\".format(i, train_batches / 2), end='', flush=True)\n",
    "                \n",
    "            # Use half training dataset\n",
    "            if i >= train_batches / 2:\n",
    "                break\n",
    "                \n",
    "            inputs, labels = data\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = vgg(inputs)\n",
    "            print(\"OUTPUTS OF VGG\")\n",
    "            print(outputs.shape)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_train += loss.data\n",
    "            acc_train += torch.sum(preds == labels.data)\n",
    "            \n",
    "            del inputs, labels, outputs, preds\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        print()\n",
    "        # * 2 as we only used half of the dataset\n",
    "        avg_loss = loss_train * 2 / dataset_sizes[TRAIN]\n",
    "        avg_acc = acc_train * 2 / dataset_sizes[TRAIN]\n",
    "        \n",
    "        # For validation\n",
    "\n",
    "        vgg.train(False)\n",
    "        vgg.eval()\n",
    "            \n",
    "        for i, data in enumerate(dataloaders[VAL]):\n",
    "            if i % 100 == 0:\n",
    "                print(\"\\rValidation batch {}/{}\".format(i, val_batches), end='', flush=True)\n",
    "                \n",
    "            inputs, labels = data\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = vgg(inputs)\n",
    "            \n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss_val += loss.data\n",
    "            acc_val += torch.sum(preds == labels.data)\n",
    "            \n",
    "            del inputs, labels, outputs, preds\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        avg_loss_val = loss_val / dataset_sizes[VAL]\n",
    "        avg_acc_val = acc_val / dataset_sizes[VAL]\n",
    "\n",
    "        # For test\n",
    "        vgg.train(False)\n",
    "        vgg.eval()\n",
    "            \n",
    "        for i, data in enumerate(dataloaders[TEST]):\n",
    "            if i % 100 == 0:\n",
    "                print(\"\\rTest batch {}/{}\".format(i, test_batches), end='', flush=True)\n",
    "                \n",
    "            inputs, labels = data\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = vgg(inputs)\n",
    "            \n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss_test += loss.data\n",
    "            acc_test += torch.sum(preds == labels.data)\n",
    "            \n",
    "            del inputs, labels, outputs, preds\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        avg_loss_test = loss_test / dataset_sizes[TEST]\n",
    "        avg_acc_test = acc_test / dataset_sizes[TEST]\n",
    "        \n",
    "        print()\n",
    "        print(\"Epoch {} result: \".format(epoch))\n",
    "        print(\"Avg loss (train): {:.4f}\".format(avg_loss))\n",
    "        print(\"Avg acc (train): {:.4f}\".format(avg_acc))\n",
    "        accuracy_train_list.append(avg_acc)\n",
    "        loss_train_list.append(avg_loss)\n",
    "        print(\"Avg loss (val): {:.4f}\".format(avg_loss_val))\n",
    "        print(\"Avg acc (val): {:.4f}\".format(avg_acc_val))\n",
    "        accuracy_val_list.append(avg_acc_val)\n",
    "        loss_val_list.append(avg_loss_val)\n",
    "        print(\"Avg loss (test): {:.4f}\".format(avg_loss_test))\n",
    "        print(\"Avg acc (test): {:.4f}\".format(avg_acc_test))\n",
    "        accuracy_test_list.append(avg_acc_test)\n",
    "        loss_test_list.append(avg_loss_test)\n",
    "        print('-' * 10)\n",
    "        print()\n",
    "        \n",
    "        if avg_acc_val > best_acc:\n",
    "            best_acc = avg_acc_val\n",
    "            best_model_wts = copy.deepcopy(vgg.state_dict())\n",
    "        \n",
    "    elapsed_time = time.time() - since\n",
    "    print()\n",
    "    print(\"Training completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
    "    print(\"Best acc: {:.4f}\".format(best_acc))\n",
    "    \n",
    "    vgg.load_state_dict(best_model_wts)\n",
    "    return vgg, accuracy_test_list, loss_test_list, accuracy_train_list, loss_train_list,accuracy_val_list, loss_val_list,num_epoch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RQBdM_hnsysY",
    "outputId": "47f1e03b-621a-47b1-f986-4d2f91c25a09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1\n",
      "----------\n",
      "Training batch 0/42.5OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n",
      "OUTPUTS OF VGG\n",
      "torch.Size([8, 2])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e568faf2afa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvgg16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# torch.save(vgg16.state_dict(), 'VGG16_v2-OCT_Retina_half_dataset.pt')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-4f81affb7996>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(vgg, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m     \"\"\"\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vgg16, accuracy_test, loss_test, accuracy_train, loss_train,accuracy_val, loss_val,num_epoch = train_model(vgg16, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=1)\n",
    "# torch.save(vgg16.state_dict(), 'VGG16_v2-OCT_Retina_half_dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fFLcxAIzvHXh"
   },
   "outputs": [],
   "source": [
    "plt.plot(num_epoch,accuracy_test, label='Test')\n",
    "plt.plot(num_epoch,accuracy_train, label='Train')\n",
    "plt.plot(num_epoch,accuracy_val, label='Val')\n",
    "plt.legend()\n",
    "plt.title(\"Epoch vs Accuracy\")\n",
    "plt.xlabel(\"No. of Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "plt.plot(num_epoch,loss_test, label='Test')\n",
    "plt.plot(num_epoch,loss_train, label='Train')\n",
    "plt.plot(num_epoch,loss_val, label='Val')\n",
    "plt.legend()\n",
    "plt.title(\"Epoch vs Loss\")\n",
    "plt.xlabel(\"No. of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_9umqngYs4Ca"
   },
   "outputs": [],
   "source": [
    "eval_model(vgg16, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNpLCrNz0tfl"
   },
   "outputs": [],
   "source": [
    "visualize_model(vgg16, num_images=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WihReWaki2l7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "VGG_random.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "033ba8d1a4c2449096a0aa411f15e5a1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ef40ac1e3d843df89ee5335d5e823aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "584424c415974ffcaa57b0edabfb935f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fe916e4124e445bb94b8e793ef10b4da",
       "IPY_MODEL_f340498a1f134a61994d9fa7cca7a5ac"
      ],
      "layout": "IPY_MODEL_033ba8d1a4c2449096a0aa411f15e5a1"
     }
    },
    "d21fe11619044580a636962bbbb12c3f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e96a369280d04ff2afbc6a21e21fdd9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f340498a1f134a61994d9fa7cca7a5ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d21fe11619044580a636962bbbb12c3f",
      "placeholder": "",
      "style": "IPY_MODEL_0ef40ac1e3d843df89ee5335d5e823aa",
      "value": " 528M/528M [00:44&lt;00:00, 12.5MB/s]"
     }
    },
    "fbae6d6f42764431b264159951494b4f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe916e4124e445bb94b8e793ef10b4da": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fbae6d6f42764431b264159951494b4f",
      "max": 553507836,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e96a369280d04ff2afbc6a21e21fdd9c",
      "value": 553507836
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
